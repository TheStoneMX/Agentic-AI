{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome to Week 6 Day 3!\n",
    "\n",
    "Let's experiment with a bunch more MCP Servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace\n",
    "from agents.mcp import MCPServerStdio\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from datetime import datetime\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first type of MCP Server: runs locally, everything local\n",
    "\n",
    "Here's a really interesting one: a knowledge-graph based memory.\n",
    "\n",
    "It's a persistent memory store of entities, observations about them, and relationships between them.\n",
    "\n",
    "https://github.com/modelcontextprotocol/servers/tree/main/src/memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='create_entities', description='Create new entities with observations and optional embeddings', inputSchema={'type': 'object', 'properties': {'entities': {'type': 'array', 'items': {'type': 'object', 'properties': {'name': {'type': 'string'}, 'entityType': {'type': 'string'}, 'observations': {'type': 'array', 'items': {'type': 'string'}}, 'embedding': {'type': 'array', 'items': {'type': 'number'}, 'description': 'Optional vector embedding for similarity search'}}, 'required': ['name', 'entityType', 'observations']}}}, 'required': ['entities']}, annotations=None),\n",
       " Tool(name='search_nodes', description='Search for entities and their relations using text or vector similarity', inputSchema={'type': 'object', 'properties': {'query': {'oneOf': [{'type': 'string', 'description': 'Text search query'}, {'type': 'array', 'items': {'type': 'number'}, 'description': 'Vector for similarity search'}]}}, 'required': ['query']}, annotations=None),\n",
       " Tool(name='read_graph', description='Get recent entities and their relations', inputSchema={'type': 'object', 'properties': {}, 'required': []}, annotations=None),\n",
       " Tool(name='create_relations', description='Create relations between entities', inputSchema={'type': 'object', 'properties': {'relations': {'type': 'array', 'items': {'type': 'object', 'properties': {'source': {'type': 'string'}, 'target': {'type': 'string'}, 'type': {'type': 'string'}}, 'required': ['source', 'target', 'type']}}}, 'required': ['relations']}, annotations=None),\n",
       " Tool(name='delete_entity', description='Delete an entity and all its associated data (observations and relations)', inputSchema={'type': 'object', 'properties': {'name': {'type': 'string', 'description': 'Name of the entity to delete'}}, 'required': ['name']}, annotations=None),\n",
       " Tool(name='delete_relation', description='Delete a specific relation between entities', inputSchema={'type': 'object', 'properties': {'source': {'type': 'string', 'description': 'Source entity name'}, 'target': {'type': 'string', 'description': 'Target entity name'}, 'type': {'type': 'string', 'description': 'Type of relation'}}, 'required': ['source', 'target', 'type']}, annotations=None)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"command\": \"npx\",\"args\": [\"-y\", \"mcp-memory-libsql\"],\"env\": {\"LIBSQL_URL\": \"file:./memory/ed.db\"}}\n",
    "\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as server:\n",
    "    mcp_tools = await server.list_tools()\n",
    "\n",
    "mcp_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You use your entity tools as a persistent memory to store and recall information about your conversations.\"\n",
    "request = \"My name's Ed. I'm an LLM engineer. I'm teaching a course about AI Agents, including the incredible MCP protocol. \\\n",
    "MCP is a protocol for connecting agents with tools, resources and prompt templates, and makes it easy to integrate AI agents with capabilities.\"\n",
    "model = \"gpt-4.1-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Nice to meet you, Ed! It's great that you're teaching a course on AI Agents, especially covering the MCP protocol. If you want, I can help you organize materials or provide additional information about AI Agents or the MCP protocol. How can I assist you further with your course?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I know that you are Ed, an LLM engineer, and you are teaching a course about AI Agents. Is there anything else you'd like to share or update about yourself?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, \"My name's Ed. What do you know about me?\")\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the trace:\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 2nd type of MCP server - runs locally, calls a web service\n",
    "\n",
    "### Brave Search - apologies - this will need another API key! But it's free again.\n",
    "\n",
    "https://brave.com/search/api/\n",
    "\n",
    "Set up your account, and put your key in the .env under `BRAVE_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = {\"BRAVE_API_KEY\": os.getenv(\"BRAVE_API_KEY\")}\n",
    "params = {\"command\": \"npx\", \"args\": [\"-y\", \"@modelcontextprotocol/server-brave-search\"], \"env\": env}\n",
    "\n",
    "async with MCPServerStdio(params=params) as server:\n",
    "    mcp_tools = await server.list_tools()\n",
    "\n",
    "mcp_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You are able to search the web for information and briefly summarize the takeaways.\"\n",
    "request = f\"Please research the latest news on Amazon stock price and briefly summarize its outlook. \\\n",
    "For context, the current date is {datetime.now().strftime('%Y-%m-%d')}\"\n",
    "model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As usual, check out the trace:\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now the third type: running remotely\n",
    "\n",
    "It's actually really hard to find a \"remote MCP server\" aka \"hosted MCP server\" aka \"managed MCP server\".\n",
    "\n",
    "It's not a common model for using or sharing MCP servers, and there isn't a standard way to discover remote MCP servers.\n",
    "\n",
    "Anthropic lists some remote MCP servers, but these are for paid applications with business users:\n",
    "\n",
    "https://docs.anthropic.com/en/docs/agents-and-tools/remote-mcp-servers\n",
    "\n",
    "CloudFlare has tooling for you to create and deploy your own remote MCP servers, but this does not seem to be a common practice:\n",
    "\n",
    "https://developers.cloudflare.com/agents/guides/remote-mcp-server/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And back to the 2nd type: the Polygon.io MCP Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">PLEASE READ!!-</h2>\n",
    "            <span style=\"color:#ff7800;\">This service for financial market data has both a FREE plan and a PAID plan, and we can use either depending on your appetite.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW SECTION: Introducing polygon.io\n",
    "\n",
    "Polygon.io is a hugely popular financial data provider. It has a free plan and a paid plan. And it also has an MCP Server!\n",
    "\n",
    "First, read up on polygon.io on their excellent website, including looking at their pricing:\n",
    "\n",
    "https://polygon.io\n",
    "\n",
    "### Polygon.io Part 1: Polygon.io free service (the paid will be totally optional, of course!)\n",
    "\n",
    "1. Please sign up for polygon.io (top right)  \n",
    "2. Once signed in, please select \"Keys\" in the left hand navigation\n",
    "3. Press the blue \"New Key\" button\n",
    "4. Copy the key name\n",
    "5. Edit your .env file and add the row:\n",
    "\n",
    "`POLYGON_API_KEY=xxxx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "polygon_api_key = os.getenv(\"POLYGON_API_KEY\")\n",
    "if not polygon_api_key:\n",
    "    print(\"POLYGON_API_KEY is not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreviousCloseAgg(ticker='AAPL', close=233.33, high=235, low=230.43, open=231.07, timestamp=1755115200000, volume=69878546.0, vwap=232.7762)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from polygon import RESTClient\n",
    "client = RESTClient(polygon_api_key)\n",
    "client.get_previous_close_agg(\"AAPL\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapped into a python module that caches end of day prices\n",
    "\n",
    "I've made a python module `market.py` that uses this API to look up share prices.\n",
    "\n",
    "But the free API is quite heavily rate limited - so I've been a bit sneaky; when you ask for a share price, this function retrieves the entire end-of-day equity market, and caches it in our database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233.33"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from market import get_share_price\n",
    "get_share_price(\"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233.33"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no rate limiting concerns!\n",
    "\n",
    "for i in range(1000):\n",
    "    get_share_price(\"AAPL\")\n",
    "get_share_price(\"AAPL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And I've made this into an MCP Server\n",
    "\n",
    "Just as we did with accounts.py; see `market_server.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error initializing MCP server: Connection closed\n"
     ]
    },
    {
     "ename": "McpError",
     "evalue": "Connection closed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMcpError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m params = {\u001b[33m\"\u001b[39m\u001b[33mcommand\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33margs\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33mrun\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmarket_server.py\u001b[39m\u001b[33m\"\u001b[39m]}\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m MCPServerStdio(params=params) \u001b[38;5;28;01mas\u001b[39;00m server:\n\u001b[32m      3\u001b[39m     mcp_tools = \u001b[38;5;28;01mawait\u001b[39;00m server.list_tools()\n\u001b[32m      4\u001b[39m mcp_tools\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/agents/lib/python3.11/site-packages/agents/mcp/server.py:98\u001b[39m, in \u001b[36m_MCPServerWithClientSession.__aenter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.connect()\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/agents/lib/python3.11/site-packages/agents/mcp/server.py:126\u001b[39m, in \u001b[36m_MCPServerWithClientSession.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    115\u001b[39m read, write, *_ = transport\n\u001b[32m    117\u001b[39m session = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.exit_stack.enter_async_context(\n\u001b[32m    118\u001b[39m     ClientSession(\n\u001b[32m    119\u001b[39m         read,\n\u001b[32m   (...)\u001b[39m\u001b[32m    124\u001b[39m     )\n\u001b[32m    125\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m server_result = \u001b[38;5;28;01mawait\u001b[39;00m session.initialize()\n\u001b[32m    127\u001b[39m \u001b[38;5;28mself\u001b[39m.server_initialize_result = server_result\n\u001b[32m    128\u001b[39m \u001b[38;5;28mself\u001b[39m.session = session\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/agents/lib/python3.11/site-packages/mcp/client/session.py:133\u001b[39m, in \u001b[36mClientSession.initialize\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    119\u001b[39m sampling = (\n\u001b[32m    120\u001b[39m     types.SamplingCapability()\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampling_callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _default_sampling_callback\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m )\n\u001b[32m    124\u001b[39m roots = (\n\u001b[32m    125\u001b[39m     \u001b[38;5;66;03m# TODO: Should this be based on whether we\u001b[39;00m\n\u001b[32m    126\u001b[39m     \u001b[38;5;66;03m# _will_ send notifications, or only whether\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    130\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    131\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.send_request(\n\u001b[32m    134\u001b[39m     types.ClientRequest(\n\u001b[32m    135\u001b[39m         types.InitializeRequest(\n\u001b[32m    136\u001b[39m             method=\u001b[33m\"\u001b[39m\u001b[33minitialize\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    137\u001b[39m             params=types.InitializeRequestParams(\n\u001b[32m    138\u001b[39m                 protocolVersion=types.LATEST_PROTOCOL_VERSION,\n\u001b[32m    139\u001b[39m                 capabilities=types.ClientCapabilities(\n\u001b[32m    140\u001b[39m                     sampling=sampling,\n\u001b[32m    141\u001b[39m                     experimental=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    142\u001b[39m                     roots=roots,\n\u001b[32m    143\u001b[39m                 ),\n\u001b[32m    144\u001b[39m                 clientInfo=\u001b[38;5;28mself\u001b[39m._client_info,\n\u001b[32m    145\u001b[39m             ),\n\u001b[32m    146\u001b[39m         )\n\u001b[32m    147\u001b[39m     ),\n\u001b[32m    148\u001b[39m     types.InitializeResult,\n\u001b[32m    149\u001b[39m )\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.protocolVersion \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SUPPORTED_PROTOCOL_VERSIONS:\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    153\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnsupported protocol version from the server: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    154\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.protocolVersion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    155\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/agents/lib/python3.11/site-packages/mcp/shared/session.py:297\u001b[39m, in \u001b[36mBaseSession.send_request\u001b[39m\u001b[34m(self, request, result_type, request_read_timeout_seconds, metadata, progress_callback)\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m McpError(\n\u001b[32m    286\u001b[39m         ErrorData(\n\u001b[32m    287\u001b[39m             code=httpx.codes.REQUEST_TIMEOUT,\n\u001b[32m   (...)\u001b[39m\u001b[32m    293\u001b[39m         )\n\u001b[32m    294\u001b[39m     )\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response_or_error, JSONRPCError):\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m McpError(response_or_error.error)\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    299\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result_type.model_validate(response_or_error.result)\n",
      "\u001b[31mMcpError\u001b[39m: Connection closed"
     ]
    }
   ],
   "source": [
    "params = {\"command\": \"python\", \"args\": [\"run\", \"market_server.py\"]}\n",
    "async with MCPServerStdio(params=params) as server:\n",
    "    mcp_tools = await server.list_tools()\n",
    "mcp_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try it out!\n",
    "\n",
    "Hopefully gpt-4o-mini is smart enough to know that the symbol for Apple is AAPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You answer questions about the stock market.\"\n",
    "request = \"What's the share price of Apple?\"\n",
    "model = \"gpt-4.1-mini\"\n",
    "\n",
    "async with MCPServerStdio(params=params) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polygon.io Part 2: Paid Plan - Totally Optional!\n",
    "\n",
    "If you are interested, you can subscribe to the monthly plan to get more up to date market data, and unlimited API calls.\n",
    "\n",
    "If you do wish to do this, then it also makes sense to use the full MCP server that Polygon.io has released, to take advantage of all their functionality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\"command\": \"uvx\",\n",
    "          \"args\": [\"--from\", \"git+https://github.com/polygon-io/mcp_polygon@v0.1.0\", \"mcp_polygon\"],\n",
    "          \"env\": {\"POLYGON_API_KEY\": polygon_api_key}\n",
    "          }\n",
    "async with MCPServerStdio(params=params) as server:\n",
    "    mcp_tools = await server.list_tools()\n",
    "mcp_tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wow that's a lot of tools!\n",
    "\n",
    "Let's try them out - hopefully the sheer number of tools doesn't overwhelm gpt-4o-mini!\n",
    "\n",
    "With the $29 monthly plan, we don't have access to some of the APIs, so I've needed to specify which APIs can be called.\n",
    "\n",
    "If you've splashed out on a bigger plan, feel free to remove my extra constraint.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You answer questions about the stock market.\"\n",
    "request = \"What's the share price of Apple? Use your get_snapshot_ticker tool to get the latest price.\"\n",
    "model = \"gpt-4.1-mini\"\n",
    "\n",
    "async with MCPServerStdio(params=params) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up your .env file\n",
    "\n",
    "If you do decide to have a paid plan, please add this to your .env file to indicate:\n",
    "\n",
    "`POLYGON_PLAN=paid`\n",
    "\n",
    "And if you decide to go all the way for the realtime API, then please do:\n",
    "\n",
    "`POLYGON_PLAN=realtime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "polygon_plan = os.getenv(\"POLYGON_PLAN\")\n",
    "is_paid_polygon = polygon_plan == \"paid\"\n",
    "is_realtime_polygon = polygon_plan == \"realtime\"\n",
    "\n",
    "if is_paid_polygon:\n",
    "    print(\"You've chosen to subscribe to the paid Polygon plan, so the code will look at prices on a 15 min delay\")\n",
    "elif is_realtime_polygon:\n",
    "    print(\"Wowzer - you've chosen to subscribe to the realtime Polygon plan, so the code will look at realtime prices\")\n",
    "else:\n",
    "    print(\"According to your .env file, you've chosen to subscribe to the free Polygon plan, so the code will look at EOD prices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And that's it for today!\n",
    "\n",
    "I've removed the part of this lab that uses the \"Financial Datasets\" mcp server, because it's inferior - more expensive with fewer APIs.\n",
    "\n",
    "And this way we get to use the same provider for Free and Paid APIs.\n",
    "\n",
    "But if you want to see the code, just look in the git history for a prior version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercises</h2>\n",
    "            <span style=\"color:#ff7800;\">Explore MCP server marketplaces and integrate your own, using all 3 approaches.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
